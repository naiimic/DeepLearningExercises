{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f72bd356",
   "metadata": {},
   "source": [
    "From now on, many excercises will require a longer training time. To shorten it, you need to start getting familiar with Google Colab. It is possible to run script using the Google GPU (to do that in a colab notebook go to Runtime -> Change runtime type -> Select GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e6e281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these lines if on colab\n",
    "#!pip install dgl-cu100\n",
    "#!pip install --upgrade tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23facc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b9cf7b",
   "metadata": {},
   "source": [
    "## Exercise 3, part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d882eeb4",
   "metadata": {},
   "source": [
    "Goals of this assignment:\n",
    "\n",
    "1. Basic introduction to the DGL library https://www.dgl.ai/\n",
    "2. Train a classifier that takes a point cloud as input (you must achieve validation accuracy over 85%)\n",
    "3. Learn to work with dgl graphs, node data and batching\n",
    "4. Build a deepset architecture with dgl mean_nodes and broadcast_nodes functions\n",
    "\n",
    "First step, download the dataset. It's a modified version of the MNIST dataset where the images have been converted to point clouds.\n",
    "\n",
    "<b> The task is to classify each graph and say which number it represents. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6c91ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip ../../Datasets/Dataset_MNIST.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149e2547",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02b306c",
   "metadata": {},
   "source": [
    "### DataSet\n",
    "\n",
    "It is already built in, but it's good to have a look at how DLG graph is created. The graphs:\n",
    "\n",
    "* have no edges, they are just a collection of nodes;\n",
    "\n",
    "* their nodes have a feature which is named \"xy\", which represents the position of the node in 2D space.\n",
    "\n",
    "The dataset will return a graph and a target class (from 0 to 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd3e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_hdf('Dataset/training_ds.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae68db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddf398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.LongTensor(training_df.label)\n",
    "n_points = training_df.n_points.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09007dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5015f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2ee449",
   "metadata": {},
   "source": [
    "Import the Dataloader already created now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d64d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import PointCloudMNISTdataset, collate_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a952d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = PointCloudMNISTdataset('Dataset/training_ds.h5')\n",
    "validation_dataset = PointCloudMNISTdataset('Dataset/valid_ds.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9c0360",
   "metadata": {},
   "outputs": [],
   "source": [
    "g, y = training_dataset[663]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc34b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph 663 has 93 nodes, no edges and each node is associated with a property 'xy'\n",
    "\n",
    "g, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076b2aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To see the 2D array of coordinates\n",
    "#g.ndata['xy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeda4b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(4,4))\n",
    "\n",
    "xy = g.ndata['xy'].data.numpy()\n",
    "\n",
    "ax.scatter( xy[:,0],xy[:,1] )\n",
    "\n",
    "ax.set_ylabel('Y ',fontsize=20,rotation=0)\n",
    "ax.set_xlabel('X',fontsize=20)\n",
    "ax.set_xlim(-1,1)\n",
    "ax.set_ylim(-1,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4741a2",
   "metadata": {},
   "source": [
    "###  How to batch?\n",
    "\n",
    "We need to batch our data in a \"special\" way, we have to tell the pytorch dataloader how to do it. We do this with the collate_graphs function defined in dataloader.py. It uses a function called dgl.batch( ). The batched graph includes all the nodes from all the graphs - and dgl keeps track of which nodes belong to each graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e351dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "data_loader = DataLoader(training_dataset, batch_size=300, shuffle=True,\n",
    "                         collate_fn=collate_graphs)\n",
    "validation_data_loader = DataLoader(validation_dataset, batch_size=300, shuffle=False,\n",
    "                         collate_fn=collate_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea8f031",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batched_g,y in data_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c474b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_g,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9fbf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_g.batch_num_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74112a8",
   "metadata": {},
   "source": [
    "## The model: DeepSets\n",
    "\n",
    "### Explanation of the structure\n",
    "\n",
    "A possible model is DeepSets (feel free to implement this or change it). \n",
    "\n",
    "<img src=\"deepset.jpeg\" width=\"800\" height=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12df20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batched_g,y in data_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b35237",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(batched_g.ndata['xy']), batched_g.ndata['xy'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f227d1ea",
   "metadata": {},
   "source": [
    "The input array is N points with features (in this case xy, so 2 dimensions). We need to be able to apply a network to each one of the nodes in the graph. We do that by applying a linear layer to the node features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ad1e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of creation of the embedding\n",
    "\n",
    "linear_layer = nn.Linear(2,10)\n",
    "# You store the output on the graph itself\n",
    "batched_g.ndata['hidden rep'] = linear_layer(batched_g.ndata['xy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b954ec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_g.ndata['hidden rep'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddafcae2",
   "metadata": {},
   "source": [
    "Next, we need to be able to take the mean of the hidden represenations in each graph - dgl has a function to do that dgl.mean_nodes( ). This function knows that our graph is a batch of different graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd1959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It extrapolates the graph you are interested in from the total graph created\n",
    "mean_of_node_rep = dgl.mean_nodes(batched_g,'hidden rep')\n",
    "mean_of_node_rep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cafc85",
   "metadata": {},
   "source": [
    "We need to be able to \"broadcast\" this global mean back to each of the individual nodes, so that they are \"aware\" of the rest of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1170636",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcasted_sum = dgl.broadcast_nodes(batched_g,mean_of_node_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6910dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcasted_sum.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9387a7a1",
   "metadata": {},
   "source": [
    "We assign this broadcasted global rep as a feature of the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45d42d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_g.ndata['global rep'] = broadcasted_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74972e3c",
   "metadata": {},
   "source": [
    "Now we can use it as input for a new linear layer, and we can update the hidden rep for each node. Now the hidden rep for each node contains information from the entire graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5077831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer2 = nn.Linear(10*2,10)\n",
    "\n",
    "input_to_layer = torch.cat([\n",
    "                            batched_g.ndata['global rep'], \n",
    "                            batched_g.ndata['hidden rep']],dim=1)\n",
    "\n",
    "batched_g.ndata['hidden rep'] = linear_layer2(input_to_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf43041",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_g.ndata['hidden rep'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870d5b4e",
   "metadata": {},
   "source": [
    "### What model should you build?\n",
    "\n",
    "The final model should take a graph as input and return a vector of length 10 (remember this is MNIST and our task is to classify digits. This model worked for me, feel free to do whatever you desire.\n",
    "\n",
    "<img src=\"model_example.jpeg\" width=\"800\" height=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34449ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cc7715",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a812440",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batched_g,y in data_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7749edfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "net(batched_g).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c4ffcb",
   "metadata": {},
   "source": [
    "## Training and testing the model\n",
    "\n",
    "Remeber, the threshold is 85%!!!\n",
    "\n",
    "Nothing changes here (the 'CUDA' parts will allow you to use the GPU on colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8da9c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.00005) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94783f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_and_loss(dataloader,net):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "    net.eval()\n",
    "    \n",
    "    n_batches = 0\n",
    "    with torch.no_grad():\n",
    "        for batched_g,y in dataloader:\n",
    "            n_batches+=1\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                batched_g = batched_g.to(torch.device('cuda'))\n",
    "                y = y.cuda()\n",
    "            pred = net(batched_g)\n",
    "            \n",
    "            loss+= loss_func(pred,y).item()\n",
    "            \n",
    "            pred = torch.argmax(pred,dim=1)\n",
    "\n",
    "            correct+=len(torch.where(pred==y)[0])\n",
    "            total+=len(y)\n",
    "    loss = loss/n_batches      \n",
    "    return correct/total, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5944c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1bb471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run it on colab\n",
    "# you have to import the .py files and afterwards you need to download the trained_model.pt that it produces\n",
    "\n",
    "if torch.cuda.is_available() == True:\n",
    "\n",
    "    n_epochs = 30\n",
    "\n",
    "    training_loss_vs_epoch = []\n",
    "    validation_loss_vs_epoch = []\n",
    "\n",
    "    training_acc_vs_epoch = []\n",
    "    validation_acc_vs_epoch = []\n",
    "\n",
    "    pbar = tqdm( range(n_epochs) )\n",
    "\n",
    "    for epoch in pbar:\n",
    "\n",
    "        if len(validation_loss_vs_epoch) > 1:\n",
    "            pbar.set_description('val acc:'+'{0:.5f}'.format(validation_acc_vs_epoch[-1])+', train acc:'+'{0:.5f}'.format(training_acc_vs_epoch[-1]))\n",
    "\n",
    "        net.train() # put the net into \"training mode\"\n",
    "        for batched_g,y in data_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                batched_g = batched_g.to(torch.device('cuda'))\n",
    "                y = y.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = net(batched_g)\n",
    "            loss = loss_func(pred,y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        net.eval() #put the net into evaluation mode\n",
    "        train_acc, train_loss = compute_accuracy_and_loss(data_loader,net)\n",
    "        valid_acc, valid_loss = compute_accuracy_and_loss(validation_data_loader,net)\n",
    "\n",
    "        training_loss_vs_epoch.append(train_loss)    \n",
    "        training_acc_vs_epoch.append(train_acc)\n",
    "\n",
    "        validation_acc_vs_epoch.append(valid_acc)\n",
    "\n",
    "        validation_loss_vs_epoch.append(valid_loss)\n",
    "        if len(validation_loss_vs_epoch)==1 or validation_loss_vs_epoch[-2] > validation_loss_vs_epoch[-1]:\n",
    "            torch.save(net.state_dict(), 'trained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3582c2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available() == True:\n",
    "    \n",
    "    fig,ax = plt.subplots(1,2,figsize=(8,3))\n",
    "\n",
    "    ax[0].plot(training_loss_vs_epoch,label='training')\n",
    "    ax[0].plot(validation_loss_vs_epoch,label='validation')\n",
    "\n",
    "    ax[1].plot(training_acc_vs_epoch)\n",
    "    ax[1].plot(validation_acc_vs_epoch)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7647c1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('trained_model.pt',map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e27124a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55173262",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_on_dataset('Dataset/valid_ds.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85097417",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
